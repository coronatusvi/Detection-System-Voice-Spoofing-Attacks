# filepath: /streamlit-audio-recorder/src/demo.py

import io
import os
import streamlit as st
from st_audiorec import st_audiorec
from voice_spoof_detection import compute_hash, get_model, run_model, AudioProcessor
import numpy as np
import torchaudio
import torch

st.set_page_config(page_title="Detection System Voice Spoofing Attacks")

def audiorec_demo_app():
    st.title('H·ªá th·ªëng ph√°t hi·ªán t·∫•n c√¥ng gi·∫£ m·∫°o gi·ªçng n√≥i')
    st.markdown('Implemented by [VI&HA]')
    st.write('\n\n')

    # Thu √¢m tr·ª±c ti·∫øp
    st.subheader("üé§ Record Audio")
    wav_audio_data = st_audiorec()

    if wav_audio_data is not None:
        temp_file_path = os.path.join("file_input", "recorded_audio.wav")
        with open(temp_file_path, "wb") as f:
            f.write(wav_audio_data)

        try:
            with st.spinner("ƒêang ph√¢n t√≠ch..."):
                # ƒê·ªçc v√† x·ª≠ l√Ω file √¢m thanh
                waveform, sample_rate = torchaudio.load(temp_file_path)

                # N·∫øu waveform l√† stereo, chuy·ªÉn sang mono
                if waveform.shape[0] > 1:
                    waveform = torch.mean(waveform, dim=0, keepdim=True)

                # Resample n·∫øu c·∫ßn
                if sample_rate != 16000:
                    waveform = torchaudio.functional.resample(waveform, sample_rate, 16000)

                # Ch·∫°y m√¥ h√¨nh
                likelihood = run_model(waveform.numpy())

                # Hi·ªÉn th·ªã k·∫øt qu·∫£ v·ªõi c·∫£nh b√°o
                if likelihood > 70:
                    st.error(f"üö® **Kh·∫£ nƒÉng l√† gi·ªçng gi·∫£:** {likelihood:.1f}% ‚ùó")
                elif likelihood > 40:
                    st.warning(f"‚ö†Ô∏è **Kh·∫£ nƒÉng l√† gi·ªçng gi·∫£:** {likelihood:.1f}% ‚ö†Ô∏è")
                else:
                    st.success(f"‚úîÔ∏è **Kh·∫£ nƒÉng l√† gi·ªçng gi·∫£:** {likelihood:.1f}% ‚úîÔ∏è")
        finally:
            if os.path.exists(temp_file_path):
                os.remove(temp_file_path)

    # T·∫£i l√™n file √¢m thanh
    st.subheader("üìÅ Upload Audio Files")
    uploaded_files = st.file_uploader(
        "Ch·ªçn file .wav ho·∫∑c .flac",
        type=["wav", "flac"],
        accept_multiple_files=True
    )

    if uploaded_files:
        if len(uploaded_files) > 10:
            st.error("B·∫°n ch·ªâ ƒë∆∞·ª£c ch·ªçn t·ªëi ƒëa 10 file.")
        else:
            results = []
            with st.spinner("ƒêang ph√¢n t√≠ch..."):
                # X·ª≠ l√Ω t·ª´ng file
                for uf in uploaded_files:
                    uf.seek(0)
                    name = uf.name
                    ext = name.rsplit(".", 1)[-1].lower()
                    wav, sample_rate = torchaudio.load(uf, format="flac" if ext == "flac" else None, backend="soundfile")

                    # Resample n·∫øu c·∫ßn
                    if sample_rate != 16000:
                        wav = torchaudio.functional.resample(wav, sample_rate, 16000)

                    # Ch·∫°y m√¥ h√¨nh
                    prob = run_model(wav.numpy())
                    results.append((uf, name, prob))

            # Hi·ªÉn th·ªã k·∫øt qu·∫£ ph√¢n t√≠ch
            st.subheader("K·∫øt qu·∫£ ph√¢n t√≠ch")
            for file_obj, name, prob in results:
                if prob > 45:
                    sym, col = "‚ùó", "red"
                elif prob > 30:
                    sym, col = "‚ö†Ô∏è", "orange"
                else:
                    sym, col = "‚úîÔ∏è", "green"
                st.markdown(
                    f"- **{name}**: <span style='color:{col};'>{prob:.2f}% {sym}</span>",
                    unsafe_allow_html=True
                )
                with st.expander(f"üîä Nghe l·∫°i {name}"):
                    st.audio(file_obj, format=f"audio/{ext}")

if __name__ == '__main__':
    audiorec_demo_app()